# [START] Instru√ß√µes para Fine-tuning no Google Colab

## [LIST] Pr√©-requisitos

1. **Conta Google** com Google Drive
2. **Google Colab** (gratuito ou Pro)
3. **GPU ativada** no Colab (Runtime > Change runtime type > GPU)

## üì¶ 1. Upload dos Dados

### Op√ß√£o A: Upload Manual
1. Abra o Google Drive
2. Crie uma pasta: `Site roteiro de dispensa√ß√£o`
3. Fa√ßa upload de toda a pasta `colab_training_data`
4. Estrutura final no Drive:
```
Site roteiro de dispensa√ß√£o/
‚îú‚îÄ‚îÄ colab_training_data/
‚îÇ   ‚îú‚îÄ‚îÄ structured_data/         # JSONs originais
‚îÇ   ‚îú‚îÄ‚îÄ training_splits/         # Train/validation/test
‚îÇ   ‚îú‚îÄ‚îÄ config/                  # Configura√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ training_data.json       # Dataset unificado
‚îÇ   ‚îî‚îÄ‚îÄ COLAB_INSTRUCTIONS.md    # Este arquivo
‚îú‚îÄ‚îÄ hanseniase_fine_tuning.ipynb # Notebook principal
‚îî‚îÄ‚îÄ ... (outros arquivos)
```

### Op√ß√£o B: Compress√£o e Upload
```bash
# Comprimir dados (execute localmente)
cd "C:\Users\Ana\Meu Drive\Site roteiro de dispensa√ß√£o"
zip -r hanseniase_training_data.zip colab_training_data/
```

## [FIX] 2. Configura√ß√£o do Colab

### 2.1 Abrir Notebook
1. V√° para [Google Colab](https://colab.research.google.com/)
2. File > Upload notebook
3. Selecione `hanseniase_fine_tuning.ipynb`
4. Ou use o link direto no notebook

### 2.2 Verificar GPU
```python
import torch
print(f"GPU dispon√≠vel: {torch.cuda.is_available()}")
print(f"GPU nome: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}")
```

### 2.3 Montar Google Drive
```python
from google.colab import drive
drive.mount('/content/drive')
```

## [REPORT] 3. Estrutura dos Dados

### 3.1 Dataset Principal (`training_data.json`)
```json
{
  "training_examples": [
    {
      "instruction": "Como Dr. Gasnelio, responda tecnicamente:",
      "input": "O que √© PQT-U?",
      "output": "PQT-U (Poliquimioterapia √önica)...",
      "source": "frequently_asked_questions.json",
      "category": "qa",
      "persona_target": "dr_gasnelio",
      "subcategory": "medicamentos"
    }
  ],
  "statistics": {...},
  "splits": {...}
}
```

### 3.2 Training Splits
- `train.json`: 57 exemplos para treinamento
- `validation.json`: 7 exemplos para valida√ß√£o  
- `test.json`: 8 exemplos para teste

### 3.3 Structured Data (JSONs originais)
- `clinical_taxonomy.json`: Taxonomia m√©dica
- `dosing_protocols.json`: Protocolos de dosagem
- `frequently_asked_questions.json`: FAQ com personas
- `medications_mechanisms.json`: Mecanismos farmacol√≥gicos
- E outros...

## ‚öôÔ∏è 4. Configura√ß√µes de Treinamento

### 4.1 Modelo Base
```python
MODEL_NAME = "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
```

**Alternativas dispon√≠veis:**
- `microsoft/DialoGPT-medium` (conversacional)
- `neuralmind/bert-base-portuguese-cased` (portugu√™s)
- `google/flan-t5-base` (instruction-following)

### 4.2 Configura√ß√£o LoRA
```python
lora_config = LoraConfig(
    r=16,                    # Rank (ajustar conforme GPU)
    lora_alpha=32,          # Scaling factor
    lora_dropout=0.1,       # Regulariza√ß√£o
    target_modules=[...]    # Camadas a treinar
)
```

### 4.3 Training Arguments
```python
training_args = TrainingArguments(
    num_train_epochs=3,
    per_device_train_batch_size=2,  # Ajustar conforme GPU
    learning_rate=2e-4,
    gradient_accumulation_steps=4,  # Simular batch maior
    # ... outras configura√ß√µes
)
```

## [TARGET] 5. Personas e Formata√ß√£o

### 5.1 Dr. Gasnelio (T√©cnico)
```
### Instru√ß√£o:
Como Dr. Gasnelio, responda tecnicamente:

### Pergunta:
Qual o mecanismo de a√ß√£o da rifampicina?

### Resposta:
[Resposta t√©cnica com terminologia m√©dica]
```

### 5.2 G√° (Emp√°tico)
```
### Instru√ß√£o:
Como G√°, responda de forma simples e emp√°tica:

### Pergunta:
Por que minha urina ficou laranja?

### Resposta:
[Resposta simples e tranquilizadora]
```

## üìà 6. Monitoramento

### 6.1 M√©tricas Principais
- **Loss de Treinamento**: Deve diminuir consistentemente
- **Loss de Valida√ß√£o**: N√£o deve aumentar (overfitting)
- **Perplexity**: < 3.0 √© desej√°vel
- **GPU Memory**: Monitorar para evitar OOM

### 6.2 Logs Esperados
```
Epoch 1/3:
[10/20] Loss: 2.45, LR: 1.8e-4
[20/20] Loss: 1.95, LR: 2.0e-4
Validation Loss: 1.87
```

## [FIX] 7. Troubleshooting

### 7.1 Out of Memory (OOM)
**Sintomas:** `CUDA out of memory`
**Solu√ß√µes:**
```python
# Reduzir batch size
per_device_train_batch_size=1

# Reduzir max_length
max_length=256

# Ativar gradient checkpointing
gradient_checkpointing=True

# Usar quantiza√ß√£o mais agressiva
load_in_8bit=True
```

### 7.2 Treinamento Lento
**Sintomas:** >5 min por √©poca
**Solu√ß√µes:**
- Verificar se GPU est√° ativada
- Reduzir n√∫mero de exemplos de treino
- Aumentar batch size se poss√≠vel
- Usar modelo menor

### 7.3 Loss n√£o Diminui
**Sintomas:** Loss constante ap√≥s v√°rias √©pocas
**Solu√ß√µes:**
```python
# Aumentar learning rate
learning_rate=5e-4

# Reduzir weight decay
weight_decay=0.0001

# Verificar formata√ß√£o dos dados
# Adicionar mais exemplos de treino
```

### 7.4 Respostas Incoerentes
**Sintomas:** Modelo gera texto irrelevante
**Solu√ß√µes:**
- Verificar formata√ß√£o do prompt
- Ajustar temperature (0.3-0.8)
- Treinar por mais √©pocas
- Validar qualidade dos dados

## [SAVE] 8. Export e Deploy

### 8.1 Salvar Modelo
```python
# Merge LoRA weights
merged_model = model.merge_and_unload()

# Salvar no Drive
merged_model.save_pretrained("/content/drive/MyDrive/hanseniase_model")
tokenizer.save_pretrained("/content/drive/MyDrive/hanseniase_model")
```

### 8.2 Download Local
1. Compacte o modelo treinado
2. Download via Google Drive
3. Integre no backend Python

## [REPORT] 9. Avalia√ß√£o de Qualidade

### 9.1 Testes Manuais
```python
# Teste Dr. Gasnelio
prompt = "Como Dr. Gasnelio, responda tecnicamente: O que √© rifampicina?"
response = generate_text(prompt)

# Teste G√°  
prompt = "Como G√°, responda de forma simples: Por que tomo 3 rem√©dios?"
response = generate_text(prompt)
```

### 9.2 M√©tricas Autom√°ticas
- **BLEU Score**: Similaridade com respostas de refer√™ncia
- **ROUGE**: Overlap de n-gramas
- **BERTScore**: Similaridade sem√¢ntica

### 9.3 Crit√©rios de Sucesso
[OK] **Aceit√°vel:**
- Loss de valida√ß√£o < 2.0
- Respostas coerentes em 80% dos testes
- Mant√©m persona caracter√≠stica

[STAR] **Excelente:**
- Loss de valida√ß√£o < 1.5
- Respostas coerentes em 95% dos testes
- Informa√ß√µes m√©dicas precisas

## [TARGET] 10. Pr√≥ximos Passos

1. **Executar notebook completo** (2-4 horas)
2. **Avaliar qualidade** das respostas
3. **Ajustar hiperpar√¢metros** se necess√°rio
4. **Retreinar** com mais dados se dispon√≠vel
5. **Integrar** no backend de produ√ß√£o
6. **Coletar feedback** dos usu√°rios
7. **Iterar** e melhorar continuamente

## üìû Suporte

- **Documenta√ß√£o Colab:** https://colab.research.google.com/
- **Transformers:** https://huggingface.co/docs/transformers/
- **PEFT:** https://huggingface.co/docs/peft/
- **Troubleshooting:** Verificar logs no notebook

---

**üè• Boa sorte com o fine-tuning especializado em hansen√≠ase! üè•**

*Gerado em: 2025-08-17*  
*Vers√£o: Q2-2025-ML-MODERNIZATION*