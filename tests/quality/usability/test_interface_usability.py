#!/usr/bin/env python3
"""
Testes de Usabilidade da Interface
UX/UI Testing Specialist & Accessibility Expert

Data: 27 de Janeiro de 2025
Fase: 5.1.3 - Testes de usabilidade
"""

import sys
import os
import time
import json
import requests
from pathlib import Path
from datetime import datetime

# Configura√ß√µes de teste
FRONTEND_URL = "http://localhost:3000"
BACKEND_URL = "http://localhost:5000"
TEST_TIMEOUT = 10

def log(message: str, level: str = "INFO"):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] [{level}] {message}")

class UsabilityTester:
    """
    Suite de testes de usabilidade e experi√™ncia do usu√°rio
    """
    
    def __init__(self):
        self.test_results = {
            'persona_switching': {'score': 0, 'issues': []},
            'responsiveness': {'score': 0, 'issues': []},
            'performance': {'score': 0, 'issues': []},
            'communication_clarity': {'score': 0, 'issues': []},
            'overall_score': 0
        }
    
    def test_persona_switching_ease(self):
        """
        Testa facilidade de troca de personas
        """
        log("INICIANDO TESTE DE TROCA DE PERSONAS", "INFO")
        print("=" * 60)
        
        switching_criteria = {
            'api_persona_switch': False,
            'response_time_acceptable': False,
            'different_responses': False,
            'consistent_identity': False,
            'error_handling': False
        }
        
        # Teste 1: Verificar endpoint de personas dispon√≠vel
        try:
            response = requests.get(f"{BACKEND_URL}/api/personas", timeout=TEST_TIMEOUT)
            if response.status_code == 200:
                personas_data = response.json()
                if 'personas' in personas_data and len(personas_data['personas']) >= 2:
                    switching_criteria['api_persona_switch'] = True
                    print("‚úÖ API de personas: Dispon√≠vel")
                else:
                    print("‚ùå API de personas: Resposta incompleta")
            else:
                print(f"‚ùå API de personas: Status {response.status_code}")
        except Exception as e:
            print(f"‚ùå API de personas: Erro - {e}")
        
        # Teste 2: Verificar tempo de resposta na troca
        if switching_criteria['api_persona_switch']:
            test_question = "Qual a dose de rifampicina para adultos?"
            
            # Testar Dr. Gasnelio
            start_time = time.time()
            try:
                payload = {'question': test_question, 'personality_id': 'dr_gasnelio'}
                response1 = requests.post(f"{BACKEND_URL}/api/chat", json=payload, timeout=TEST_TIMEOUT)
                gasnelio_time = time.time() - start_time
                
                if response1.status_code == 200 and gasnelio_time < 8:
                    switching_criteria['response_time_acceptable'] = True
                    print(f"‚úÖ Tempo Dr. Gasnelio: {gasnelio_time:.2f}s")
                else:
                    print(f"‚ùå Tempo Dr. Gasnelio: {gasnelio_time:.2f}s (muito lento)")
                
                # Testar G√°
                start_time = time.time()
                payload = {'question': test_question, 'personality_id': 'ga'}
                response2 = requests.post(f"{BACKEND_URL}/api/chat", json=payload, timeout=TEST_TIMEOUT)
                ga_time = time.time() - start_time
                
                if response2.status_code == 200 and ga_time < 8:
                    print(f"‚úÖ Tempo G√°: {ga_time:.2f}s")
                    
                    # Verificar se as respostas s√£o diferentes
                    if response1.json().get('answer') != response2.json().get('answer'):
                        switching_criteria['different_responses'] = True
                        print("‚úÖ Respostas diferenciadas: Confirmado")
                    else:
                        print("‚ùå Respostas diferenciadas: Muito similares")
                else:
                    print(f"‚ùå Tempo G√°: {ga_time:.2f}s (muito lento)")
                    
            except Exception as e:
                print(f"‚ùå Erro no teste de troca: {e}")
        
        # Teste 3: Verificar consist√™ncia de identidade
        identity_questions = ["Quem voc√™ √©?", "Qual seu nome?"]
        for question in identity_questions:
            try:
                payload = {'question': question, 'personality_id': 'dr_gasnelio'}
                response = requests.post(f"{BACKEND_URL}/api/chat", json=payload, timeout=TEST_TIMEOUT)
                if response.status_code == 200:
                    answer = response.json().get('answer', '').lower()
                    if 'gasnelio' in answer or 'dr.' in answer:
                        switching_criteria['consistent_identity'] = True
                        break
            except:
                pass
        
        if switching_criteria['consistent_identity']:
            print("‚úÖ Identidade consistente: Dr. Gasnelio se identifica")
        else:
            print("‚ùå Identidade consistente: Problemas de identifica√ß√£o")
        
        # Teste 4: Verificar tratamento de erros
        try:
            payload = {'question': 'teste', 'personality_id': 'persona_inexistente'}
            response = requests.post(f"{BACKEND_URL}/api/chat", json=payload, timeout=TEST_TIMEOUT)
            if response.status_code in [400, 404]:
                switching_criteria['error_handling'] = True
                print("‚úÖ Tratamento de erros: Adequado")
            else:
                print("‚ùå Tratamento de erros: Inadequado")
        except:
            print("‚ùå Tratamento de erros: Falha no teste")
        
        # Calcular score
        score = sum(switching_criteria.values()) / len(switching_criteria) * 100
        self.test_results['persona_switching']['score'] = score
        
        print(f"\nüìä SCORE TROCA DE PERSONAS: {score:.1f}%")
        return score >= 75
    
    def test_responsive_design(self):
        """
        Testa responsividade em diferentes dispositivos (estrutural)
        """
        log("INICIANDO TESTE DE RESPONSIVIDADE", "INFO")
        print("=" * 60)
        
        # Como n√£o temos acesso direto ao DOM, vamos verificar a estrutura do frontend
        frontend_path = Path("src/frontend")
        responsive_criteria = {
            'tailwind_config': False,
            'responsive_components': False,
            'mobile_first_approach': False,
            'accessibility_features': False
        }
        
        # Verificar configura√ß√£o Tailwind (framework responsivo)
        tailwind_config = frontend_path / "tailwind.config.js"
        if tailwind_config.exists():
            try:
                with open(tailwind_config, 'r', encoding='utf-8') as f:
                    content = f.read()
                if 'responsive' in content or 'screens' in content:
                    responsive_criteria['tailwind_config'] = True
                    print("‚úÖ Configura√ß√£o Tailwind: Responsiva")
                else:
                    print("‚ùå Configura√ß√£o Tailwind: N√£o responsiva")
            except:
                print("‚ùå Configura√ß√£o Tailwind: Erro na leitura")
        else:
            print("‚ùå Configura√ß√£o Tailwind: N√£o encontrada")
        
        # Verificar componentes responsivos
        components_path = frontend_path / "src" / "components"
        if components_path.exists():
            responsive_patterns = ['sm:', 'md:', 'lg:', 'xl:', 'mobile', 'tablet', 'desktop']
            responsive_files = 0
            total_files = 0
            
            for tsx_file in components_path.rglob("*.tsx"):
                total_files += 1
                try:
                    with open(tsx_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    if any(pattern in content for pattern in responsive_patterns):
                        responsive_files += 1
                except:
                    pass
            
            if total_files > 0 and responsive_files / total_files >= 0.5:
                responsive_criteria['responsive_components'] = True
                print(f"‚úÖ Componentes responsivos: {responsive_files}/{total_files}")
            else:
                print(f"‚ùå Componentes responsivos: {responsive_files}/{total_files} (insuficiente)")
        
        # Verificar abordagem mobile-first
        globals_css = frontend_path / "src" / "styles" / "globals.css"
        if globals_css.exists():
            try:
                with open(globals_css, 'r', encoding='utf-8') as f:
                    content = f.read()
                if '@media' in content or 'mobile' in content:
                    responsive_criteria['mobile_first_approach'] = True
                    print("‚úÖ Mobile-first: Detectado")
                else:
                    print("‚ùå Mobile-first: N√£o detectado")
            except:
                print("‚ùå Mobile-first: Erro na verifica√ß√£o")
        
        # Verificar recursos de acessibilidade
        accessibility_indicators = ['aria-', 'role=', 'alt=', 'tabIndex', 'accessibility']
        accessible_files = 0
        
        for tsx_file in components_path.rglob("*.tsx"):
            try:
                with open(tsx_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                if any(indicator in content for indicator in accessibility_indicators):
                    accessible_files += 1
            except:
                pass
        
        if accessible_files >= 3:  # Pelo menos 3 componentes com acessibilidade
            responsive_criteria['accessibility_features'] = True
            print(f"‚úÖ Recursos de acessibilidade: {accessible_files} componentes")
        else:
            print(f"‚ùå Recursos de acessibilidade: {accessible_files} componentes (insuficiente)")
        
        score = sum(responsive_criteria.values()) / len(responsive_criteria) * 100
        self.test_results['responsiveness']['score'] = score
        
        print(f"\nüìä SCORE RESPONSIVIDADE: {score:.1f}%")
        return score >= 75
    
    def test_performance_metrics(self):
        """
        Testa performance e tempos de resposta
        """
        log("INICIANDO TESTE DE PERFORMANCE", "INFO")
        print("=" * 60)
        
        performance_criteria = {
            'backend_health_fast': False,
            'api_response_time': False,
            'frontend_bundle_size': False,
            'resource_optimization': False
        }
        
        # Teste 1: Health check do backend
        try:
            start_time = time.time()
            response = requests.get(f"{BACKEND_URL}/api/health", timeout=5)
            health_time = time.time() - start_time
            
            if response.status_code == 200 and health_time < 2:
                performance_criteria['backend_health_fast'] = True
                print(f"‚úÖ Health check: {health_time:.3f}s")
            else:
                print(f"‚ùå Health check: {health_time:.3f}s (muito lento)")
        except Exception as e:
            print(f"‚ùå Health check: Erro - {e}")
        
        # Teste 2: Tempo de resposta da API de chat
        try:
            start_time = time.time()
            payload = {'question': 'O que √© hansen√≠ase?', 'personality_id': 'ga'}
            response = requests.post(f"{BACKEND_URL}/api/chat", json=payload, timeout=15)
            api_time = time.time() - start_time
            
            if response.status_code == 200:
                if api_time < 10:  # Aceit√°vel para chatbot m√©dico
                    performance_criteria['api_response_time'] = True
                    print(f"‚úÖ Tempo API chat: {api_time:.2f}s")
                else:
                    print(f"‚ùå Tempo API chat: {api_time:.2f}s (muito lento)")
            else:
                print(f"‚ùå API chat: Status {response.status_code}")
        except Exception as e:
            print(f"‚ùå API chat: Erro - {e}")
        
        # Teste 3: Verificar tamanho do bundle frontend
        dist_path = Path("src/frontend/dist")
        if dist_path.exists():
            total_size = 0
            js_files = 0
            
            for file in dist_path.rglob("*.js"):
                try:
                    size = file.stat().st_size
                    total_size += size
                    js_files += 1
                except:
                    pass
            
            # Converter para MB
            total_mb = total_size / (1024 * 1024)
            
            if total_mb < 5:  # Menos de 5MB √© bom para uma aplica√ß√£o
                performance_criteria['frontend_bundle_size'] = True
                print(f"‚úÖ Bundle size: {total_mb:.2f}MB ({js_files} arquivos)")
            else:
                print(f"‚ùå Bundle size: {total_mb:.2f}MB (muito grande)")
        else:
            print("‚ö†Ô∏è Bundle size: Dist n√£o encontrado (frontend n√£o compilado)")
        
        # Teste 4: Verificar otimiza√ß√µes de recursos
        package_json = Path("src/frontend/package.json")
        if package_json.exists():
            try:
                with open(package_json, 'r', encoding='utf-8') as f:
                    package_data = json.load(f)
                
                # Verificar depend√™ncias de otimiza√ß√£o
                optimization_deps = ['vite', '@vitejs/plugin-react', 'terser']
                deps = {**package_data.get('dependencies', {}), **package_data.get('devDependencies', {})}
                
                optimizations = sum(1 for dep in optimization_deps if dep in deps)
                
                if optimizations >= 2:
                    performance_criteria['resource_optimization'] = True
                    print(f"‚úÖ Otimiza√ß√µes: {optimizations} ferramentas detectadas")
                else:
                    print(f"‚ùå Otimiza√ß√µes: {optimizations} ferramentas (insuficiente)")
            except:
                print("‚ùå Otimiza√ß√µes: Erro na verifica√ß√£o")
        
        score = sum(performance_criteria.values()) / len(performance_criteria) * 100
        self.test_results['performance']['score'] = score
        
        print(f"\nüìä SCORE PERFORMANCE: {score:.1f}%")
        return score >= 75
    
    def test_communication_clarity(self):
        """
        Testa clareza da comunica√ß√£o e feedback visual
        """
        log("INICIANDO TESTE DE CLAREZA DA COMUNICA√á√ÉO", "INFO")
        print("=" * 60)
        
        communication_criteria = {
            'error_messages_clear': False,
            'loading_states': False,
            'persona_identification': False,
            'user_guidance': False
        }
        
        # Teste 1: Verificar mensagens de erro claras
        try:
            # Tentar requisi√ß√£o inv√°lida
            payload = {'invalid': 'data'}
            response = requests.post(f"{BACKEND_URL}/api/chat", json=payload, timeout=TEST_TIMEOUT)
            
            if response.status_code >= 400:
                error_data = response.json() if response.content else {}
                if 'error' in error_data or 'message' in error_data:
                    communication_criteria['error_messages_clear'] = True
                    print("‚úÖ Mensagens de erro: Claras")
                else:
                    print("‚ùå Mensagens de erro: N√£o estruturadas")
            else:
                print("‚ùå Mensagens de erro: N√£o test√°veis")
        except:
            print("‚ùå Mensagens de erro: Erro no teste")
        
        # Teste 2: Verificar estados de loading no frontend
        frontend_components = Path("src/frontend/src/components")
        loading_indicators = ['Loading', 'Spinner', 'isLoading', 'loading']
        
        loading_components = 0
        for tsx_file in frontend_components.rglob("*.tsx"):
            try:
                with open(tsx_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                if any(indicator in content for indicator in loading_indicators):
                    loading_components += 1
            except:
                pass
        
        if loading_components >= 2:
            communication_criteria['loading_states'] = True
            print(f"‚úÖ Estados de loading: {loading_components} componentes")
        else:
            print(f"‚ùå Estados de loading: {loading_components} componentes (insuficiente)")
        
        # Teste 3: Verificar identifica√ß√£o clara das personas
        try:
            gasnelio_test = {'question': 'Quem voc√™ √©?', 'personality_id': 'dr_gasnelio'}
            response = requests.post(f"{BACKEND_URL}/api/chat", json=gasnelio_test, timeout=TEST_TIMEOUT)
            
            if response.status_code == 200:
                answer = response.json().get('answer', '').lower()
                if 'gasnelio' in answer or 'farmac√™utico' in answer:
                    communication_criteria['persona_identification'] = True
                    print("‚úÖ Identifica√ß√£o de personas: Clara")
                else:
                    print("‚ùå Identifica√ß√£o de personas: Confusa")
        except:
            print("‚ùå Identifica√ß√£o de personas: Erro no teste")
        
        # Teste 4: Verificar orienta√ß√µes ao usu√°rio
        persona_components = frontend_components.rglob("*Persona*.tsx")
        guidance_elements = ['tooltip', 'placeholder', 'helper', 'hint', 'guide']
        
        guidance_found = False
        for component in persona_components:
            try:
                with open(component, 'r', encoding='utf-8') as f:
                    content = f.read()
                if any(element in content.lower() for element in guidance_elements):
                    guidance_found = True
                    break
            except:
                pass
        
        if guidance_found:
            communication_criteria['user_guidance'] = True
            print("‚úÖ Orienta√ß√µes ao usu√°rio: Presentes")
        else:
            print("‚ùå Orienta√ß√µes ao usu√°rio: Ausentes")
        
        score = sum(communication_criteria.values()) / len(communication_criteria) * 100
        self.test_results['communication_clarity']['score'] = score
        
        print(f"\nüìä SCORE CLAREZA DA COMUNICA√á√ÉO: {score:.1f}%")
        return score >= 75
    
    def generate_usability_report(self):
        """
        Gera relat√≥rio final de usabilidade
        """
        log("GERANDO RELAT√ìRIO DE USABILIDADE", "INFO")
        
        # Calcular score geral
        scores = [
            self.test_results['persona_switching']['score'],
            self.test_results['responsiveness']['score'],
            self.test_results['performance']['score'],
            self.test_results['communication_clarity']['score']
        ]
        
        overall_score = sum(scores) / len(scores)
        self.test_results['overall_score'] = overall_score
        
        print("\n" + "=" * 80)
        print("üìã RELAT√ìRIO FINAL DE USABILIDADE - FASE 5.1.3")
        print("=" * 80)
        
        print(f"\nüîÑ TROCA DE PERSONAS: {self.test_results['persona_switching']['score']:.1f}%")
        print(f"üì± RESPONSIVIDADE: {self.test_results['responsiveness']['score']:.1f}%")
        print(f"‚ö° PERFORMANCE: {self.test_results['performance']['score']:.1f}%")
        print(f"üí¨ CLAREZA DA COMUNICA√á√ÉO: {self.test_results['communication_clarity']['score']:.1f}%")
        
        print(f"\nüìä SCORE GERAL DE USABILIDADE: {overall_score:.1f}%")
        
        if overall_score >= 85:
            certification = "EXCELENTE - PRONTO PARA PRODU√á√ÉO"
        elif overall_score >= 75:
            certification = "BOM - APROVADO COM PEQUENOS AJUSTES"
        elif overall_score >= 65:
            certification = "REGULAR - NECESSITA MELHORIAS"
        else:
            certification = "INSUFICIENTE - REQUER CORRE√á√ïES SIGNIFICATIVAS"
        
        print(f"üéØ CERTIFICA√á√ÉO: {certification}")
        
        # Salvar relat√≥rio
        report_path = Path("tests/quality/usability/usability_report.md")
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"""# Relat√≥rio de Usabilidade - Fase 5.1.3

**Data:** {datetime.now().strftime("%d de %B de %Y")}
**Especialista:** UX/UI Testing Specialist & Accessibility Expert
**Score Geral:** {overall_score:.1f}%

## Resultados dos Testes

### üîÑ Troca de Personas: {self.test_results['persona_switching']['score']:.1f}%
- Facilidade de altern√¢ncia entre Dr. Gasnelio e G√°
- Tempo de resposta aceit√°vel
- Diferencia√ß√£o clara entre personas

### üì± Responsividade: {self.test_results['responsiveness']['score']:.1f}%
- Design adapt√°vel para diferentes dispositivos
- Configura√ß√£o mobile-first
- Recursos de acessibilidade

### ‚ö° Performance: {self.test_results['performance']['score']:.1f}%
- Tempos de resposta do backend
- Otimiza√ß√£o do frontend
- Tamanho do bundle de produ√ß√£o

### üí¨ Clareza da Comunica√ß√£o: {self.test_results['communication_clarity']['score']:.1f}%
- Mensagens de erro claras
- Estados de carregamento
- Orienta√ß√µes ao usu√°rio

## Certifica√ß√£o Final
**{certification}**

## Recomenda√ß√µes
{"- Sistema aprovado para produ√ß√£o com usabilidade excelente" if overall_score >= 85 else "- Implementar melhorias identificadas antes da produ√ß√£o"}

---
*Relat√≥rio gerado automaticamente pelo sistema de testes de usabilidade*
""")
        
        print(f"\nüìÑ Relat√≥rio salvo em: {report_path}")
        return overall_score >= 75

def main():
    """
    Executa suite completa de testes de usabilidade
    """
    print("=" * 80)
    print("TESTES DE USABILIDADE - FASE 5.1.3")
    print("UX/UI Testing Specialist & Accessibility Expert")
    print("=" * 80)
    print()
    
    tester = UsabilityTester()
    
    try:
        print("üöÄ INICIANDO SUITE DE TESTES DE USABILIDADE")
        print()
        
        # Executar todos os testes
        tests = [
            ("Facilidade de Troca de Personas", tester.test_persona_switching_ease),
            ("Responsividade da Interface", tester.test_responsive_design),
            ("Performance e Tempos de Resposta", tester.test_performance_metrics),
            ("Clareza da Comunica√ß√£o", tester.test_communication_clarity)
        ]
        
        results = []
        for test_name, test_func in tests:
            print(f"\nüìã EXECUTANDO: {test_name}")
            print("-" * 60)
            
            try:
                result = test_func()
                results.append(result)
                status = "APROVADO" if result else "REQUER ATEN√á√ÉO"
                print(f"Resultado: {status}")
            except Exception as e:
                print(f"ERRO: {e}")
                results.append(False)
            
            print()
        
        # Gerar relat√≥rio final
        success = tester.generate_usability_report()
        
        print("\n" + "=" * 80)
        if success:
            print("‚úÖ TESTES DE USABILIDADE: APROVADOS")
            print("Sistema possui boa usabilidade para produ√ß√£o!")
        else:
            print("‚ö†Ô∏è TESTES DE USABILIDADE: REQUEREM ATEN√á√ÉO")
            print("Melhorias de usabilidade necess√°rias.")
        print("=" * 80)
        
        return success
        
    except Exception as e:
        log(f"ERRO durante execu√ß√£o: {e}", "ERROR")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)