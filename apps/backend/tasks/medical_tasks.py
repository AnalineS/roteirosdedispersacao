# -*- coding: utf-8 -*-
"""
Medical Tasks - Tasks assíncronas para processamento médico
Análise de documentos, backup de dados e relatórios médicos
"""

from celery import current_task
from celery_config import celery_app
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import json
import sqlite3
from pathlib import Path

logger = logging.getLogger(__name__)

@celery_app.task(bind=True, name='medical.process_document')
def process_medical_document_async(self, file_path: str, document_type: str, user_id: str) -> Dict[str, Any]:
    """
    Processamento assíncrono de documentos médicos
    OCR + análise + indexação
    """
    try:
        # Atualizar progresso
        self.update_state(
            state='PROGRESS',
            meta={
                'stage': 'ocr_processing',
                'progress': 10,
                'message': 'Iniciando processamento OCR...',
                'file_path': file_path
            }
        )

        # Import do processador multimodal
        try:
            from services.integrations.multimodal_processor import get_multimodal_processor
            processor = get_multimodal_processor()
        except ImportError:
            raise Exception("Processador multimodal não disponível")

        # Processar documento
        self.update_state(
            state='PROGRESS',
            meta={
                'stage': 'analyzing',
                'progress': 30,
                'message': 'Analisando conteúdo médico...'
            }
        )

        # Aqui normalmente faria o processamento real
        # Por simplicidade, vou simular
        result = {
            'document_id': f"doc_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'file_path': file_path,
            'document_type': document_type,
            'user_id': user_id,
            'processed_at': datetime.now().isoformat(),
            'ocr_text': "Texto extraído do documento médico...",
            'medical_entities': ['hanseníase', 'PQT-U', 'rifampicina'],
            'confidence_score': 0.85,
            'status': 'completed'
        }

        # Salvar no SQLite
        self.update_state(
            state='PROGRESS',
            meta={
                'stage': 'saving',
                'progress': 80,
                'message': 'Salvando análise no banco...'
            }
        )

        _save_document_analysis(result)

        self.update_state(
            state='SUCCESS',
            meta={
                'stage': 'completed',
                'progress': 100,
                'message': 'Documento processado com sucesso!',
                'result': result
            }
        )

        return result

    except Exception as e:
        logger.error(f"[MEDICAL_TASK] Erro ao processar documento: {e}")
        self.update_state(
            state='FAILURE',
            meta={
                'stage': 'error',
                'progress': 0,
                'message': f'Erro: {str(e)}'
            }
        )
        raise

@celery_app.task(bind=True, name='medical.backup_sqlite')
def backup_sqlite_database_async(self, backup_name: Optional[str] = None) -> Dict[str, Any]:
    """
    Backup assíncrono do banco SQLite
    """
    try:
        self.update_state(
            state='PROGRESS',
            meta={
                'stage': 'preparing',
                'progress': 5,
                'message': 'Preparando backup do banco SQLite...'
            }
        )

        # Configurar paths
        db_path = Path('./data/roteiros.db')
        backup_dir = Path('./data/backups')
        backup_dir.mkdir(exist_ok=True)

        if not backup_name:
            backup_name = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"

        backup_path = backup_dir / backup_name

        self.update_state(
            state='PROGRESS',
            meta={
                'stage': 'backing_up',
                'progress': 25,
                'message': f'Criando backup: {backup_name}...'
            }
        )

        # Realizar backup
        if db_path.exists():
            import shutil
            shutil.copy2(db_path, backup_path)

            # Verificar integridade
            self.update_state(
                state='PROGRESS',
                meta={
                    'stage': 'verifying',
                    'progress': 75,
                    'message': 'Verificando integridade do backup...'
                }
            )

            # Teste de conexão no backup
            try:
                conn = sqlite3.connect(backup_path)
                conn.execute("SELECT COUNT(*) FROM sqlite_master")
                conn.close()
                integrity_ok = True
            except:
                integrity_ok = False

            result = {
                'backup_name': backup_name,
                'backup_path': str(backup_path),
                'original_size': db_path.stat().st_size,
                'backup_size': backup_path.stat().st_size,
                'created_at': datetime.now().isoformat(),
                'integrity_ok': integrity_ok,
                'status': 'completed' if integrity_ok else 'warning'
            }

            # Upload para Cloud Storage se configurado
            self.update_state(
                state='PROGRESS',
                meta={
                    'stage': 'uploading',
                    'progress': 90,
                    'message': 'Enviando para Cloud Storage...'
                }
            )

            try:
                cloud_path = _upload_backup_to_cloud(backup_path)
                result['cloud_path'] = cloud_path
            except Exception as e:
                logger.warning(f"Falha no upload para cloud: {e}")
                result['cloud_upload'] = f"Falha: {e}"

        else:
            raise Exception(f"Banco de dados não encontrado: {db_path}")

        return result

    except Exception as e:
        logger.error(f"[BACKUP_TASK] Erro no backup: {e}")
        self.update_state(
            state='FAILURE',
            meta={
                'stage': 'error',
                'progress': 0,
                'message': f'Erro no backup: {str(e)}'
            }
        )
        raise

@celery_app.task(bind=True, name='medical.generate_analytics')
def generate_medical_analytics_async(self, date_range: int = 30) -> Dict[str, Any]:
    """
    Geração assíncrona de relatórios e analytics médicos
    """
    try:
        self.update_state(
            state='PROGRESS',
            meta={
                'stage': 'collecting',
                'progress': 10,
                'message': f'Coletando dados dos últimos {date_range} dias...'
            }
        )

        # Simular coleta de dados do SQLite
        analytics_data = _collect_medical_analytics(date_range)

        self.update_state(
            state='PROGRESS',
            meta={
                'stage': 'analyzing',
                'progress': 40,
                'message': 'Analisando padrões de uso...'
            }
        )

        # Análise de padrões
        patterns = _analyze_usage_patterns(analytics_data)

        self.update_state(
            state='PROGRESS',
            meta={
                'stage': 'generating_report',
                'progress': 70,
                'message': 'Gerando relatório final...'
            }
        )

        # Gerar relatório
        report = {
            'report_id': f"analytics_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'date_range': date_range,
            'generated_at': datetime.now().isoformat(),
            'metrics': {
                'total_questions': analytics_data.get('total_questions', 0),
                'unique_users': analytics_data.get('unique_users', 0),
                'avg_response_time': analytics_data.get('avg_response_time', 0),
                'top_topics': patterns.get('top_topics', []),
                'persona_usage': patterns.get('persona_usage', {}),
                'error_rate': patterns.get('error_rate', 0)
            },
            'recommendations': _generate_recommendations(patterns),
            'status': 'completed'
        }

        # Salvar relatório
        self.update_state(
            state='PROGRESS',
            meta={
                'stage': 'saving',
                'progress': 90,
                'message': 'Salvando relatório...'
            }
        )

        _save_analytics_report(report)

        return report

    except Exception as e:
        logger.error(f"[ANALYTICS_TASK] Erro na geração de analytics: {e}")
        self.update_state(
            state='FAILURE',
            meta={
                'stage': 'error',
                'progress': 0,
                'message': f'Erro: {str(e)}'
            }
        )
        raise

# Funções auxiliares
def _save_document_analysis(analysis: Dict[str, Any]) -> None:
    """Salva análise de documento no SQLite"""
    try:
        db_path = './data/roteiros.db'
        conn = sqlite3.connect(db_path)

        # Criar tabela se não existir
        conn.execute('''
            CREATE TABLE IF NOT EXISTS document_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                document_id TEXT UNIQUE,
                file_path TEXT,
                document_type TEXT,
                user_id TEXT,
                processed_at TEXT,
                ocr_text TEXT,
                medical_entities TEXT,
                confidence_score REAL,
                status TEXT
            )
        ''')

        # Inserir análise
        conn.execute('''
            INSERT OR REPLACE INTO document_analysis
            (document_id, file_path, document_type, user_id, processed_at,
             ocr_text, medical_entities, confidence_score, status)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            analysis['document_id'],
            analysis['file_path'],
            analysis['document_type'],
            analysis['user_id'],
            analysis['processed_at'],
            analysis['ocr_text'],
            json.dumps(analysis['medical_entities']),
            analysis['confidence_score'],
            analysis['status']
        ))

        conn.commit()
        conn.close()

    except Exception as e:
        logger.error(f"Erro ao salvar análise: {e}")

def _upload_backup_to_cloud(backup_path: Path) -> str:
    """Upload de backup para Cloud Storage"""
    # Por enquanto simular - integraria com Cloud Storage real
    cloud_path = f"gs://roteiros-backups/{backup_path.name}"
    logger.info(f"[SIMULATED] Upload para: {cloud_path}")
    return cloud_path

def _collect_medical_analytics(date_range: int) -> Dict[str, Any]:
    """Coleta dados para analytics"""
    # Simular coleta de dados
    return {
        'total_questions': 1250,
        'unique_users': 85,
        'avg_response_time': 2.3,
        'date_range': date_range
    }

def _analyze_usage_patterns(data: Dict[str, Any]) -> Dict[str, Any]:
    """Análise de padrões de uso"""
    return {
        'top_topics': ['dosagem PQT-U', 'efeitos colaterais', 'interações'],
        'persona_usage': {'dr_gasnelio': 65, 'ga': 35},
        'error_rate': 0.02
    }

def _generate_recommendations(patterns: Dict[str, Any]) -> List[str]:
    """Gera recomendações baseadas nos padrões"""
    return [
        "Considerar mais conteúdo sobre dosagem PQT-U",
        "Melhorar respostas sobre efeitos colaterais",
        "Balancear uso entre personas"
    ]

def _save_analytics_report(report: Dict[str, Any]) -> None:
    """Salva relatório de analytics no SQLite"""
    try:
        db_path = './data/roteiros.db'
        conn = sqlite3.connect(db_path)

        # Criar tabela se não existir
        conn.execute('''
            CREATE TABLE IF NOT EXISTS analytics_reports (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                report_id TEXT UNIQUE,
                date_range INTEGER,
                generated_at TEXT,
                metrics TEXT,
                recommendations TEXT,
                status TEXT
            )
        ''')

        # Inserir relatório
        conn.execute('''
            INSERT OR REPLACE INTO analytics_reports
            (report_id, date_range, generated_at, metrics, recommendations, status)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            report['report_id'],
            report['date_range'],
            report['generated_at'],
            json.dumps(report['metrics']),
            json.dumps(report['recommendations']),
            report['status']
        ))

        conn.commit()
        conn.close()

    except Exception as e:
        logger.error(f"Erro ao salvar relatório: {e}")

# Health check
@celery_app.task(name='medical.health_check')
def medical_tasks_health():
    """Health check das tasks médicas"""
    return {
        'status': 'healthy',
        'available_tasks': [
            'medical.process_document',
            'medical.backup_sqlite',
            'medical.generate_analytics'
        ],
        'timestamp': datetime.now().isoformat()
    }