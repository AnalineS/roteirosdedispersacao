Informa√ß√µes do Ambiente:
‚Ä¢	Caminho Base: C:\Users\Ana\Meu Drive\Site roteiro de dispensa√ß√£o\
‚Ä¢	Infraestrutura Atual: Google Cloud Run + Firebase
‚Ä¢	Astra DB: J√° configurado no GitHub Secrets
‚Ä¢	Estrutura de Pastas: 
o	/data - Cont√©m JSONs estruturados e documentos MD/PDF
o	/apps/backend/services - Servi√ßos do backend incluindo RAG
o	/apps/backend/core/personas - Defini√ß√µes das personas
o	/apps/backend/core/rag - Sistema RAG atual
o	/apps/backend/config - Configura√ß√µes e prompts
üìä FASE 1: SYSTEM AUDIT COMPLETO
Tarefa 1.1: An√°lise do Estado Atual
Crie e execute um script de auditoria completo que:
python
"""
Requirements:
1. Analise TODOS os arquivos nas pastas mencionadas
2. Crie um relat√≥rio detalhado do que existe
3. Identifique gaps e oportunidades
4. Verifique a qualidade dos dados
5. Teste a performance atual do RAG
"""

# system_audit.py
import os
import json
import time
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple
import pandas as pd

BASE_PATH = r"C:\Users\Ana\Meu Drive\Site roteiro de dispensa√ß√£o"

def execute_complete_audit():
    """
    Execute as seguintes verifica√ß√µes:
    
    1. DATA AUDIT:
       - Listar todos os JSONs em /data/structured/
       - Para cada JSON:
         * Contar n√∫mero de entradas
         * Verificar completude dos campos
         * Identificar campos √∫nicos
         * Calcular tamanho em tokens
       - Arquivos espec√≠ficos para verificar:
         * clinical_taxonomy.json
         * dispensing_workflow.json
         * dosing_protocols.json
         * frequently_asked_questions.json
         * hanseniase_catalog.json
         * knowledge_scope_limitations.json
         * medications_mechanisms.json
         * pharmacovigilance_guidelines.json
         * quick_reference_protocols.json
    
    2. DOCUMENTS AUDIT:
       - Verificar exist√™ncia e tamanho de:
         * Roteiro de Dsipensa√ß√£o - Hansen√≠ase.md
         * Roteiro de Dsipensa√ß√£o - Hansen√≠ase.pdf
         * roteiro_hanseniase_basico.md
       - Contar p√°ginas/linhas
       - Extrair estrutura de t√≥picos
    
    3. BACKEND SERVICES AUDIT:
       - Analisar cada arquivo .py em /apps/backend/services/
       - Identificar:
         * Classes e m√©todos principais
         * Depend√™ncias importadas
         * Integra√ß√µes com APIs externas
         * Uso de cache
       - Arquivos cr√≠ticos:
         * enhanced_rag_system.py
         * medical_rag_integration.py
         * vector_store.py
         * embedding_service.py
         * semantic_search.py
    
    4. PERSONAS AUDIT:
       - Verificar /apps/backend/core/personas/:
         * dr_gasnelio.py
         * ga_empathetic.py
         * persona_manager.py
       - Extrair prompts e caracter√≠sticas
    
    5. CONFIG AUDIT:
       - Analisar /apps/backend/config/:
         * dr_gasnelio_technical_prompt.py
         * ga_empathetic_prompt.py
         * thesis_reference_system.py
       - Verificar vari√°veis de ambiente necess√°rias
    
    6. PERFORMANCE BASELINE:
       - Simular 10 queries comuns
       - Medir lat√™ncia m√©dia
       - Verificar taxa de erro
       - Testar ambas as personas
    
    Gere um relat√≥rio em formato JSON e Markdown com:
    - Resumo executivo
    - Invent√°rio completo de arquivos
    - M√©tricas de qualidade dos dados
    - Gaps identificados
    - Recomenda√ß√µes priorit√°rias
    """
    
    # Implemente o c√≥digo completo aqui
    pass

# Execute e salve o relat√≥rio
if __name__ == "__main__":
    audit_report = execute_complete_audit()
    
    # Salvar relat√≥rios
    with open('audit_report.json', 'w', encoding='utf-8') as f:
        json.dump(audit_report, f, indent=2, ensure_ascii=False)
    
    with open('audit_report.md', 'w', encoding='utf-8') as f:
        f.write(generate_markdown_report(audit_report))
Tarefa 1.2: An√°lise de Qualidade dos Dados
python
"""
Analise a qualidade dos dados para fine-tuning:

1. Para cada arquivo JSON em /data/structured/:
   - Valide schema
   - Identifique dados faltantes
   - Calcule estat√≠sticas (min, max, m√©dia de campos)
   - Verifique duplicatas
   - Identifique inconsist√™ncias

2. Crie um dataset unificado:
   - Combine todos os JSONs relevantes
   - Normalize formato
   - Adicione metadados (source, category, persona_target)
   - Exporte como training_data.json

3. Gere m√©tricas:
   - Total de exemplos √∫nicos
   - Distribui√ß√£o por categoria
   - Cobertura de t√≥picos
   - Qualidade para fine-tuning (score 0-100)
"""
üìö FASE 2: PREPARA√á√ÉO AMBIENTE COLAB
Tarefa 2.1: Criar Notebook Colab Completo
python
"""
Crie um notebook Colab (hanseniase_fine_tuning.ipynb) com:

1. SETUP INICIAL:
   - Montagem do Google Drive
   - Instala√ß√£o de depend√™ncias
   - Verifica√ß√£o de GPU dispon√≠vel
   - Clone do reposit√≥rio

2. C√âLULAS DO NOTEBOOK:
"""

# C√©lula 1: Setup Environment
!pip install transformers==4.36.0
!pip install peft==0.7.0
!pip install bitsandbytes==0.41.0
!pip install datasets accelerate
!pip install sentencepiece protobuf

# Verificar GPU
import torch
print(f"GPU dispon√≠vel: {torch.cuda.is_available()}")
print(f"GPU Nome: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}")

# C√©lula 2: Mount Drive e Load Data
from google.colab import drive
drive.mount('/content/drive')

import sys
sys.path.append('/content/drive/MyDrive/Site roteiro de dispensa√ß√£o')

# C√©lula 3: Data Preparation
"""
Implemente:
1. Carregamento dos JSONs estruturados
2. Convers√£o para formato de training (instruction, input, output)
3. Cria√ß√£o de exemplos para cada persona
4. Data augmentation com par√°frase
5. Split train/val/test (80/10/10)
"""

# C√©lula 4: Model Configuration
"""
Configure:
1. Modelo base: 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext'
2. LoRA configuration (r=16, alpha=32)
3. Training arguments otimizados para Colab free
4. Implementa√ß√£o de checkpointing
"""

# C√©lula 5: Training Loop
"""
Implemente:
1. Training com progress bar
2. Validation a cada √©poca
3. Early stopping
4. Salvamento de checkpoints
5. Logging de m√©tricas
"""

# C√©lula 6: Evaluation
"""
Crie testes espec√≠ficos:
1. Perguntas t√©cnicas para Dr. Gasnelio
2. Perguntas simples para G√°
3. C√°lculo de m√©tricas (accuracy, perplexity, BLEU)
4. Compara√ß√£o com baseline
"""

# C√©lula 7: Export and Deploy
"""
1. Merge LoRA weights
2. Quantiza√ß√£o para int8
3. Export para ONNX (opcional)
4. Upload para Google Drive
5. Instru√ß√µes de integra√ß√£o
"""
Tarefa 2.2: Preparar Dados para Upload
python
"""
Crie um script que prepare todos os dados necess√°rios para o Colab:

1. Crie pasta organizada:
   /colab_training_data/
   ‚îú‚îÄ‚îÄ structured_data/
   ‚îÇ   ‚îî‚îÄ‚îÄ [todos os JSONs]
   ‚îú‚îÄ‚îÄ documents/
   ‚îÇ   ‚îî‚îÄ‚îÄ [MD e PDF files]
   ‚îú‚îÄ‚îÄ personas/
   ‚îÇ   ‚îî‚îÄ‚îÄ [prompts de cada persona]
   ‚îî‚îÄ‚îÄ config/
       ‚îî‚îÄ‚îÄ training_config.json

2. Comprima em training_data.zip

3. Gere instru√ß√µes de upload para Colab
"""
üöÄ FASE 3: MIGRA√á√ÉO ASTRA DB
Tarefa 3.1: Setup Astra DB Connection
python
"""
Usando as credenciais j√° configuradas no GitHub Secrets:

1. Crie o script de conex√£o:
   - Teste conex√£o com Astra DB
   - Crie keyspace 'hanseniase_rag' se n√£o existir
   - Crie tabela 'embeddings' com schema otimizado
   - Configure √≠ndices para busca vetorial

2. Valide a conex√£o:
   - Execute query de teste
   - Verifique lat√™ncia
   - Teste inser√ß√£o e busca

IMPORTANTE: verifique as secrets do GitHub e fa√ßa a equival√™ncia com essas abaixo:
- ASTRA_DB_ID
- ASTRA_DB_REGION  
- ASTRA_DB_TOKEN
- ASTRA_DB_KEYSPACE
"""

# astra_setup.py
import os
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider

def setup_astra_connection():
    # Implementar conex√£o segura
    pass

def create_vector_table():
    """
    CREATE TABLE IF NOT EXISTS embeddings (
        id UUID PRIMARY KEY,
        content TEXT,
        embedding vector<float, 768>,
        metadata MAP<TEXT, TEXT>,
        persona TEXT,
        category TEXT,
        source TEXT,
        chunk_index INT,
        created_at TIMESTAMP,
        updated_at TIMESTAMP
    )
    """
    pass
Tarefa 3.2: Migra√ß√£o de Dados
python
"""
Migre os dados existentes do vector_store.py atual:

1. Extraia todos os embeddings do sistema atual
2. Converta para formato Astra DB
3. Fa√ßa upload em batches de 100
4. Valide integridade ap√≥s migra√ß√£o
5. Crie backup antes de migrar
"""

# migrate_to_astra.py
def migrate_embeddings():
    """
    1. Backup current data
    2. Load from vector_store.py
    3. Transform to Astra format
    4. Batch upload
    5. Verify migration
    """
    pass
ü§ñ FASE 4: IMPLEMENTA√á√ÉO DE FEATURES
Tarefa 4.1: Sistema de An√°lise Preditiva
python
"""
Implemente o sistema de sugest√µes preditivas:

1. Crie regras baseadas em contexto
2. Implemente cache de sugest√µes
3. Adicione tracking de cliques
4. Integre com o frontend existente
"""

# predictive_system.py
class PredictiveEngine:
    def __init__(self):
        self.rules = self.load_context_rules()
        self.cache = {}
    
    def get_suggestions(self, context):
        # Implementar l√≥gica
        pass
Tarefa 4.2: Chatbot Multimodal
python
"""
Adicione suporte para imagens:

1. OCR para documentos m√©dicos
2. An√°lise b√°sica de imagens
3. Sistema de auto-deletion ap√≥s 7 dias
4. Disclaimers apropriados
"""

# multimodal_handler.py
class MultimodalProcessor:
    def process_image(self, image_path):
        # OCR + Analysis + Safety
        pass
üìä FASE 5: TESTES E VALIDA√á√ÉO
Tarefa 5.1: Suite de Testes Automatizados
python
"""
Crie testes para todas as funcionalidades. Importante, j√° existe uma su√≠te de teste robusta no c√≥digo:

1. Testes de unidade para cada componente
2. Testes de integra√ß√£o
3. Testes de performance
4. Testes de seguran√ßa
5. Testes de usabilidade

Use pytest e gere relat√≥rio de cobertura.
"""

# test_suite.py
import pytest

class TestCompleteSystem:
    def test_astra_connection(self):
        pass
    
    def test_rag_performance(self):
        pass
    
    def test_fine_tuned_model(self):
        pass
    
    def test_multimodal_processing(self):
        pass
üìà FASE 6: DOCUMENTA√á√ÉO E DEPLOY
Tarefa 6.1: Documenta√ß√£o Completa
python
"""
Gere documenta√ß√£o:

1. README.md atualizado
2. API documentation
3. Guia de troubleshooting
4. M√©tricas de performance
5. Changelog
"""
Tarefa 6.2: Deploy para Produ√ß√£o
python
"""
Execute o commit e git push para o deploy automatizado:

1. Update Google Cloud Run
2. Configure monitoring
3. Setup alertas
4. Valida√ß√£o em produ√ß√£o
"""
üéØ INSTRU√á√ïES DE EXECU√á√ÉO
IMPORTANTE: Execute as tarefas NA ORDEM apresentada. Cada fase depende da anterior.
Ordem de Execu√ß√£o:
1.	HOJE (Dia 1): 
o	Execute System Audit completo (Tarefa 1.1 e 1.2)
o	Prepare ambiente Colab (Tarefa 2.1 e 2.2)
o	Teste conex√£o Astra DB (Tarefa 3.1)
2.	Dia 2-3: 
o	Complete migra√ß√£o Astra DB (Tarefa 3.2)
o	Inicie fine-tuning no Colab
3.	Dia 4-5: 
o	Implemente an√°lise preditiva (Tarefa 4.1)
o	Adicione suporte multimodal (Tarefa 4.2)
4.	Dia 6-7: 
o	Execute todos os testes (Tarefa 5.1)
o	Prepare documenta√ß√£o (Tarefa 6.1)
o	Deploy para produ√ß√£o (Tarefa 6.2)
Crit√©rios de Sucesso:
‚Ä¢	Audit report completo gerado
‚Ä¢	Dados migrados para Astra DB
‚Ä¢	Modelo fine-tuned com accuracy >90%
‚Ä¢	Sugest√µes preditivas funcionando
‚Ä¢	OCR de documentos operacional
‚Ä¢	Todos os testes passando
‚Ä¢	Documenta√ß√£o completa
‚Ä¢	Sistema em produ√ß√£o
Outputs Esperados:
1.	audit_report.json e audit_report.md
2.	hanseniase_fine_tuning.ipynb (Colab notebook)
3.	training_data.zip (para Colab)
4.	migration_log.json (Astra DB)
5.	test_report.html (pytest coverage)
6.	deployment_checklist.md
Handling de Erros:
Para CADA opera√ß√£o:
1.	Implemente try-catch apropriado
2.	Fa√ßa log detalhado de erros
3.	Crie fallback quando poss√≠vel
4.	Sempre fa√ßa backup antes de mudan√ßas destrutivas
# Astra DB (j√° no GitHub Secrets)
# Google Cloud (j√° no GitHub Secrets)
# FIREBASE (j√° no GitHub Secrets)
# OpenAI/API Keys (j√° no GitHub Secrets)
üö® NOTAS CR√çTICAS
1.	SEMPRE fa√ßa backup antes de qualquer migra√ß√£o
2.	TESTE localmente antes de aplicar em produ√ß√£o
3.	DOCUMENTE todas as mudan√ßas realizadas
4.	VALIDE com dados m√©dicos reais
5.	MANTENHA os disclaimers m√©dicos em TODAS as features
‚úÖ CHECKLIST FINAL
Antes de considerar completo, verifique:
‚Ä¢	Todos os arquivos de auditoria foram gerados
‚Ä¢	Colab notebook est√° funcional e testado
‚Ä¢	Astra DB est√° recebendo e retornando queries
‚Ä¢	Fine-tuned model tem performance superior ao baseline
‚Ä¢	Features novas est√£o integradas ao sistema existente
‚Ä¢	Testes cobrem >95% do c√≥digo
‚Ä¢	Documenta√ß√£o est√° completa e atualizada
‚Ä¢	Sistema est√° rodando em produ√ß√£o sem erros